{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crime Detection Model Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "df = pd.read_csv('crime_data.csv')\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\", dayfirst=False)\n",
    "df['hour'] = pd.to_datetime(df['Time'], format='%H:%M', errors='coerce').dt.hour.fillna(0).astype(int)\n",
    "df['month'] = df['Date'].dt.month\n",
    "df['day'] = df['Date'].dt.day\n",
    "df['weekday'] = df['Date'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['crime_encoder.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode categorical variables\n",
    "le_location = LabelEncoder()\n",
    "df['Location_encoded'] = le_location.fit_transform(df['Locality_Name'])\n",
    "joblib.dump(le_location, 'location_encoder.pkl')\n",
    "\n",
    "le_crime = LabelEncoder()\n",
    "df['Crime_encoded'] = le_crime.fit_transform(df['Crime_Type'])\n",
    "joblib.dump(le_crime, 'crime_encoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection and scaling\n",
    "X = df[['Location_encoded', 'Crime_encoded', 'month', 'day', 'weekday', 'hour']].values\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "X_scaled = X_scaled.reshape((X_scaled.shape[0], X_scaled.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Conv1D + BiLSTM Autoencoder\n",
    "input_layer = tf.keras.Input(shape=(6, 1))\n",
    "x = tf.keras.layers.Conv1D(32, kernel_size=2, padding='same', activation='relu')(input_layer)\n",
    "x = tf.keras.layers.MaxPooling1D(pool_size=2, padding='same')(x)\n",
    "x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True))(x)\n",
    "x = tf.keras.layers.UpSampling1D(size=2)(x)\n",
    "x = tf.keras.layers.Conv1D(1, kernel_size=2, padding='same', activation='sigmoid')(x)\n",
    "\n",
    "autoencoder = tf.keras.Model(inputs=input_layer, outputs=x)\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "autoencoder.compile(optimizer='adam', loss=MeanSquaredError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 0.0340\n",
      "Epoch 2/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0013\n",
      "Epoch 3/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - loss: 0.0011\n",
      "Epoch 4/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 9.0618e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 7.6850e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 6.5123e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - loss: 5.3424e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - loss: 4.6325e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - loss: 4.0226e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 3.5194e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 3.0834e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 2.7196e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - loss: 2.5125e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 2.2136e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - loss: 2.0542e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - loss: 1.8591e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - loss: 1.7376e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - loss: 1.5725e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - loss: 1.4683e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - loss: 1.3497e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - loss: 1.2744e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - loss: 1.1755e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - loss: 1.1276e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - loss: 1.0363e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - loss: 9.9779e-05\n",
      "Epoch 26/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 9.7042e-05\n",
      "Epoch 27/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 9.0913e-05\n",
      "Epoch 28/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 8.8254e-05\n",
      "Epoch 29/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 8.4552e-05\n",
      "Epoch 30/30\n",
      "\u001b[1m1255/1255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 8.0173e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x27fb8e86950>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)\n",
    "autoencoder.fit(X_scaled, X_scaled, epochs=30, batch_size=32, verbose=1, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "autoencoder.save('conv_bilstm_autoencoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and calculate reconstruction error\n",
    "reconstructed = autoencoder.predict(X_scaled, verbose=0)\n",
    "mse = np.mean(np.power(X_scaled - reconstructed, 2), axis=(1, 2))\n",
    "df['reconstruction_error'] = mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top anomalies based on reconstruction error:\n",
      "    Locality_Name           Crime_Type                Date              Time  \\\n",
      "16     gachibowli         DRUG OFFENSE 2020-01-01 16:00:00  02-01-2020 02:57   \n",
      "52     gachibowli  PUBLIC INTOXICATION 2020-01-03 04:00:00  03-01-2020 22:01   \n",
      "59     Shamshabad          SHOPLIFTING 2020-01-03 11:00:00  04-01-2020 05:33   \n",
      "74       Ameerpet           CYBERCRIME 2020-01-04 02:00:00  05-01-2020 01:45   \n",
      "120      Ameerpet     VEHICLE - STOLEN 2020-01-06 00:00:00  06-01-2020 12:16   \n",
      "\n",
      "     reconstruction_error  \n",
      "16               0.000351  \n",
      "52               0.000283  \n",
      "59               0.000245  \n",
      "74               0.000320  \n",
      "120              0.000484  \n"
     ]
    }
   ],
   "source": [
    "# Identify anomalies\n",
    "threshold = np.percentile(mse, 95)\n",
    "anomalies = df[df['reconstruction_error'] > threshold]\n",
    "print(\"\\nTop anomalies based on reconstruction error:\")\n",
    "print(anomalies[['Locality_Name', 'Crime_Type', 'Date', 'Time', 'reconstruction_error']].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
